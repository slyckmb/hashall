#!/usr/bin/env python3
"""
Hierarchical auto-scan - Fast hash scanning with per-device databases.

Walks directory tree and scans each subdirectory independently with workers=8
and fast hash mode (SHA1 of first 1MB only). Provides rapid initial scanning,
better progress visibility, and zero database contention via per-device databases.

Fast hash mode: ~100,000x faster for large files (reads 1MB instead of 100GB)

Example:
  /pool/
  ‚îú‚îÄ‚îÄ movies/    ‚Üí Fast hash with workers=8 ‚Üí ~/.hashall/catalog-pool.db
  ‚îú‚îÄ‚îÄ music/     ‚Üí Fast hash with workers=8 ‚Üí ~/.hashall/catalog-pool.db
  ‚îî‚îÄ‚îÄ docs/      ‚Üí Fast hash with workers=8 ‚Üí ~/.hashall/catalog-pool.db
"""

import os
import sys
import argparse
from pathlib import Path
from tqdm import tqdm

# Add hashall to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from hashall.scan import scan_path

# Optimal configuration (benchmarked 2026-02-01)
# Fast hash: workers=12 (good for single or dual concurrent scans)
#   - Single scan (cached): ~3000 files/sec
#   - Single scan (uncached): ~84 files/sec
#   - Dual scan: 24 total workers on 16 cores = reasonable oversubscription
# Full hash: workers=2 (reading entire files, I/O saturated)
# batch_size=1000 for frequent commits and telemetry collection
SCAN_CONFIG = {"parallel": True, "workers": 12, "batch_size": 1000}


def count_files_in_directory(path: Path) -> int:
    """
    Count files directly in this directory (non-recursive).

    Returns:
        total_files_in_dir
    """
    total_files = 0

    try:
        for item in path.iterdir():
            if item.is_file():
                total_files += 1
    except (OSError, PermissionError):
        pass

    return total_files


def get_subdirectories(path: Path, max_depth: int = None, current_depth: int = 0, pbar=None):
    """
    Get all subdirectories up to max_depth.

    Args:
        path: Root path to start from
        max_depth: Maximum depth to traverse (None = unlimited)
        current_depth: Current depth in recursion
        pbar: Optional tqdm progress bar to update

    Returns:
        List of subdirectory paths
    """
    if max_depth is not None and current_depth >= max_depth:
        return []

    subdirs = []

    try:
        for item in path.iterdir():
            if item.is_dir():
                subdirs.append(item)
                if pbar is not None:
                    pbar.update(1)
                    pbar.set_postfix_str(f"depth {current_depth + 1}: {item.name[:40]}")
                if max_depth is None or current_depth + 1 < max_depth:
                    subdirs.extend(get_subdirectories(item, max_depth, current_depth + 1, pbar))
    except (OSError, PermissionError):
        pass

    return subdirs


def get_device_db_path(scan_path: Path) -> Path:
    """
    Get per-device database path for a scan path.
    Uses ~/.hashall/catalog-{device}.db to avoid I/O overhead on data drives.

    Example: /pool/data ‚Üí ~/.hashall/catalog-pool.db
             /stash/media ‚Üí ~/.hashall/catalog-stash.db
    """
    # Resolve to absolute path
    abs_path = scan_path.resolve()

    # Get path components
    parts = abs_path.parts

    # Extract device name from path (first component after root)
    if len(parts) >= 2 and parts[0] == '/':
        device_name = parts[1]
    else:
        # Fallback to 'default' if path structure is unexpected
        device_name = 'default'

    # Use ~/.hashall/catalog-{device}.db (fast SSD, not I/O-bound USB drives)
    home = Path.home()
    return home / '.hashall' / f'catalog-{device_name}.db'


def hierarchical_scan(
    root_path: Path,
    db_path: Path,
    max_depth: int = None,
    min_files: int = 10,
    dry_run: bool = False,
    per_device: bool = False
):
    """
    Hierarchical folder-by-folder scan with optimal settings.

    Args:
        root_path: Root directory to scan
        db_path: Database path (ignored if per_device=True)
        max_depth: Maximum depth to traverse (None = unlimited)
        min_files: Minimum files in a directory to warrant separate scan
        dry_run: Preview only, don't execute
        per_device: Use device-local database (e.g., /pool/.hashall/catalog.db)
    """
    # Override db_path if using per-device mode
    if per_device:
        db_path = get_device_db_path(root_path)
        print(f"üóÑÔ∏è  Using device-local database: {db_path}")

    print(f"üîç Analyzing directory tree: {root_path}")
    print(f"   Max depth: {max_depth or 'unlimited'}")
    print(f"   Min files per scan: {min_files}")
    print()

    # Get all subdirectories
    print("üìÅ Walking directory tree...")
    with tqdm(desc="   Discovering", unit=" dirs", dynamic_ncols=True) as pbar:
        all_subdirs = get_subdirectories(root_path, max_depth, pbar=pbar)
    print(f"   Found {len(all_subdirs)} subdirectories\n")

    # Build scan list (root + subdirs with enough files)
    scan_dirs = [root_path]

    # Filter subdirs by min_files
    print("üìä Counting files per directory...")
    for subdir in tqdm(all_subdirs, desc="   Checking", unit=" dirs"):
        total = count_files_in_directory(subdir)
        if total >= min_files:
            scan_dirs.append(subdir)

    total_scans = len(scan_dirs)
    print(f"\nüìã Scan Plan: {total_scans} directories (workers={SCAN_CONFIG['workers']}, fast hash)\n")

    if dry_run:
        print(f"üîß Dry-run mode: Would execute {total_scans} scans")
        return

    # Execute scans with nested progress bars
    print(f"üöÄ Starting {total_scans} scans (workers={SCAN_CONFIG['workers']}, batch={SCAN_CONFIG['batch_size']})...\n")

    # Create overall progress bar at position 0
    with tqdm(total=total_scans, desc="Overall", unit=" folders", position=0, leave=True) as overall_pbar:
        for dir_path in scan_dirs:
            rel_path = dir_path.relative_to(root_path) if dir_path != root_path else Path(".")

            # Update overall progress bar with current folder
            overall_pbar.set_postfix_str(f"{str(rel_path)[:60]}")

            # Retry logic for database lock contention
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    scan_path(
                        db_path=db_path,
                        root_path=dir_path,
                        parallel=SCAN_CONFIG['parallel'],
                        workers=SCAN_CONFIG['workers'],
                        batch_size=SCAN_CONFIG['batch_size'],
                        tqdm_position=1,  # Position 1 for nested display
                        quiet=True,  # Suppress output for clean nested progress bars
                        hash_mode='fast'  # Quick hash only for fast initial scan
                    )
                    break  # Success!
                except KeyboardInterrupt:
                    print("\n‚ö†Ô∏è  Scan interrupted by user")
                    return
                except Exception as e:
                    if "database is locked" in str(e) and attempt < max_retries - 1:
                        import time
                        wait_time = (2 ** attempt) * 1.0  # 1s, 2s, 4s
                        overall_pbar.write(f"‚è≥ Database busy, retrying in {wait_time:.0f}s... (attempt {attempt + 2}/{max_retries})")
                        time.sleep(wait_time)
                    else:
                        overall_pbar.write(f"‚ùå Scan failed: {e}")
                        break  # Give up after retries or non-lock error

            overall_pbar.update(1)

    print(f"\n‚úÖ Completed all {total_scans} scans!")


def main():
    parser = argparse.ArgumentParser(
        description="Hierarchical folder-by-folder scan with fast hash (workers=8)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
How it works:
  1. Walks directory tree to find all subdirectories
  2. Counts files in each directory
  3. Scans each directory independently with fast hash (quick_hash only)
  4. Uses workers=8 optimized for fast hash (1MB reads)
  5. Shows nested progress bars (overall folders + current folder files)
  6. Per-device databases prevent contention

Fast hash mode:
  - Computes SHA1 of first 1MB only (not entire file)
  - ~100,000x faster for large files (100GB ‚Üí 1MB read)
  - Full hash computed on-demand for collision resolution

Benefits:
  - Better progress visibility (folder-by-folder)
  - Scoped deletion detection (per-folder)
  - Resume-ability (completed folders stay done)
  - Zero database contention (per-device databases)
  - Rapid initial scanning (~10-20 mins for 60k files)

Examples:
  # Scan entire tree
  hashall-auto-scan /pool

  # Limit depth to avoid deep recursion
  hashall-auto-scan /pool --max-depth 2

  # Preview scan plan without executing
  hashall-auto-scan /pool --dry-run

  # Only scan folders with 20+ files
  hashall-auto-scan /pool --min-files 20
        """
    )

    parser.add_argument("path", type=Path, help="Root directory to scan")
    parser.add_argument(
        "--max-depth",
        type=int,
        default=None,
        help="Maximum directory depth to analyze (default: unlimited)"
    )
    parser.add_argument(
        "--min-files",
        type=int,
        default=10,
        help="Minimum files in directory to warrant separate scan (default: 10)"
    )
    parser.add_argument(
        "--db",
        type=Path,
        default=Path.home() / ".hashall" / "catalog.db",
        help="Database path (default: ~/.hashall/catalog.db)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show scan plan without executing"
    )
    parser.add_argument(
        "--per-device",
        action="store_true",
        help="Use device-local database (e.g., /pool/.hashall/catalog.db) for zero contention"
    )

    args = parser.parse_args()

    if not args.path.exists():
        print(f"‚ùå Error: Path does not exist: {args.path}")
        return 1

    if not args.path.is_dir():
        print(f"‚ùå Error: Path is not a directory: {args.path}")
        return 1

    try:
        hierarchical_scan(
            root_path=args.path,
            db_path=args.db,
            max_depth=args.max_depth,
            min_files=args.min_files,
            dry_run=args.dry_run,
            per_device=args.per_device
        )
        return 0
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Interrupted by user")
        return 130
    except Exception as e:
        print(f"\n‚ùå Failed: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
